{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C1W3_Assignment.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO7rtZ8wb/U6LtX1WagEZ9U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Moez7/IA/blob/main/C1W3_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "0WD2o6Jblro8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Fashion MNIST dataset\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV2KUIqBqAdT",
        "outputId": "49468185-213d-455a-e92d-dab470bcdc0b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: reshape_and_normalize\n",
        "\n",
        "def reshape_and_normalize(images):\n",
        "    \n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Reshape the images to add an extra dimension\n",
        "    images = images.reshape([60000, 28, 28, 1])\n",
        "    \n",
        "    # Normalize pixel values\n",
        "    images = images / 255.0;\n",
        "    \n",
        "    ### END CODE HERE\n",
        "\n",
        "    return images"
      ],
      "metadata": {
        "id": "x8el9pbaqFro"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_images = reshape_and_normalize(training_images)\n",
        "\n",
        "print(f\"Maximum pixel value after normalization: {np.max(training_images)}\\n\")\n",
        "print(f\"Shape of training set after reshaping: {training_images.shape}\\n\")\n",
        "print(f\"Shape of one image after reshaping: {training_images[0].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mbicHwUqJlS",
        "outputId": "8b6e45ee-9697-4af7-8186-6fbf0be2e2dd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum pixel value after normalization: 1.0\n",
            "\n",
            "Shape of training set after reshaping: (60000, 28, 28, 1)\n",
            "\n",
            "Shape of one image after reshaping: (28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED CLASS: myCallback\n",
        "### START CODE HERE\n",
        "\n",
        "# Remember to inherit from the correct class\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    # Define the method that checks the accuracy at the end of each epoch\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if logs.get('accuracy') is not None and logs.get('accuracy') > 0.995: \n",
        "                print(\"\\nReached 99% accuracy so cancelling training!\") \n",
        "                # Stop training once the above condition is met\n",
        "                self.model.stop_training = True\n",
        "    pass   \n",
        "\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "B-FcVoZdqSJe"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: convolutional_model\n",
        "def convolutional_model():\n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Define the model, it should have 5 layers:\n",
        "    # - A Conv2D layer with 32 filters, a kernel_size of 3x3, ReLU activation function\n",
        "    #    and an input shape that matches that of every image in the training set\n",
        "    # - A MaxPooling2D layer with a pool_size of 2x2\n",
        "    # - A Flatten layer with no arguments\n",
        "    # - A Dense layer with 128 units and ReLU activation function\n",
        "    # - A Dense layer with 10 units and softmax activation function\n",
        "    model = tf.keras.models.Sequential([ \n",
        "      tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.MaxPooling2D(2, 2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ]) \n",
        "\n",
        "    ### END CODE HERE\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', \n",
        "                  loss='sparse_categorical_crossentropy', \n",
        "                  metrics=['accuracy']) \n",
        "        \n",
        "    return model"
      ],
      "metadata": {
        "id": "jwbdXVt9rvn1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save your untrained model\n",
        "model = convolutional_model()\n",
        "\n",
        "# Instantiate the callback class\n",
        "callbacks = myCallback()\n",
        "\n",
        "# Train your model (this can take up to 5 minutes)\n",
        "history = model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_qMXIunr1qQ",
        "outputId": "3a814377-604f-4b34-b34f-5977a4819ee4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.4048 - accuracy: 0.8563\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.2754 - accuracy: 0.9015\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.2300 - accuracy: 0.9154\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 35s 18ms/step - loss: 0.1957 - accuracy: 0.9282\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.1706 - accuracy: 0.9368\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.1454 - accuracy: 0.9453\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.1245 - accuracy: 0.9542\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.1076 - accuracy: 0.9602\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0916 - accuracy: 0.9654\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0799 - accuracy: 0.9711\n"
          ]
        }
      ]
    }
  ]
}